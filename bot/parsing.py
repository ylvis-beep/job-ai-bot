import logging
import re
import time
import random
import os
from io import BytesIO
from typing import Optional, Dict, Any
from urllib.parse import urlparse

import requests
from bs4 import BeautifulSoup
from PyPDF2 import PdfReader

from config import (
    PROXY_URL, 
    MIN_MEANINGFUL_TEXT_LENGTH,
    SELENIUM_ENABLED,
    SELENIUM_TIMEOUT,
    SELENIUM_HEADLESS
)

logger = logging.getLogger(__name__)

GENERIC_VACANCY_ERROR_MSG = (
    "–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å–∞–π—Ç–∞.\n"
    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –≤—Ä—É—á–Ω—É—é."
)

# =========================
# –ü–ï–†–ï–ú–ï–ù–ù–´–ï –ò–ó ENVIRONMENT (–∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é!)
# =========================

# –ü–æ–ª—É—á–∞–µ–º –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
CLOUDSCRAPER_ENABLED = os.getenv("CLOUDSCRAPER_ENABLED", "true").lower() == "true"
FORCE_MOBILE_HH = os.getenv("FORCE_MOBILE_HH", "false").lower() == "true"
RETRY_COUNT = int(os.getenv("RETRY_COUNT", "3"))

# Headers –∫–∞–∫ –≤ —Å—Ç–∞—Ç—å–µ
BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
    "Accept-Encoding": "gzip, deflate, br",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
    "Sec-Fetch-Dest": "document",
    "Sec-Fetch-Mode": "navigate",
    "Sec-Fetch-Site": "none",
    "Sec-Fetch-User": "?1",
    "Cache-Control": "max-age=0",
}

# =========================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# =========================

def clean_text(raw: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
    if not raw:
        return ""
    text = raw.replace("\r\n", "\n").replace("\r", "\n")
    lines = [line.strip() for line in text.split("\n")]
    text = "\n".join(lines)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

def extract_text_from_pdf_bytes(data: bytes) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
    try:
        reader = PdfReader(BytesIO(data))
        pages_text = []

        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                pages_text.append(page_text)

        text = "\n\n".join(pages_text)
        text = clean_text(text)

        if not text or len(text) < 50:
            raise ValueError("PDF —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Ç–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")

        logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ PDF")
        return text

    except ValueError:
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {e}", exc_info=True)
        raise ValueError(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å PDF —Ñ–∞–π–ª. "
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç."
        )

def looks_like_url(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ URL"""
    if not text:
        return False
    text = text.strip()
    URL_REGEX = re.compile(r"^(https?://)?([a-z0-9.-]+\.[a-z]{2,})(/.*)?$", re.IGNORECASE)
    return bool(URL_REGEX.match(text))

def normalize_url(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL"""
    text = text.strip()
    if not text.startswith(("http://", "https://")):
        return "https://" + text
    return text

def html_to_text(html: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML"""
    if not html:
        return ""
    
    try:
        soup = BeautifulSoup(html, "html.parser")
        
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for element in soup(["script", "style", "nav", "footer", "header", "aside", "form", "iframe"]):
            element.decompose()
        
        text = soup.get_text(separator='\n', strip=True)
        text = clean_text(text)
        
        # –£–¥–∞–ª—è–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
        lines = [line for line in text.split('\n') if len(line.strip()) > 10]
        text = '\n'.join(lines)
        
        return text
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
        return ""

# =========================
# –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ö–°–ò
# =========================

def _format_proxy_for_requests(proxy_url: str) -> Optional[str]:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∫—Å–∏ –¥–ª—è requests"""
    if not proxy_url:
        return None
    
    proxy = proxy_url.strip()
    
    # –£–∂–µ –µ—Å—Ç—å —Å—Ö–µ–º–∞
    if proxy.startswith(('http://', 'https://', 'socks5://')):
        return proxy
    
    # –§–æ—Ä–º–∞—Ç: user:pass@host:port –∏–ª–∏ host:port@user:pass
    if '@' in proxy:
        parts = proxy.split('@')
        if len(parts) == 2:
            left, right = parts
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–¥–µ –ª–æ–≥–∏–Ω, –≥–¥–µ —Ö–æ—Å—Ç
            if ':' in left and ':' in right:
                if '.' in left:  # –ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å - —Ö–æ—Å—Ç
                    return f"http://{right}@{left}"
                else:  # –ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å - –ª–æ–≥–∏–Ω
                    return f"http://{left}@{right}"
    
    # –ü—Ä–æ—Å—Ç–æ–π host:port
    return f"http://{proxy}"

def _format_proxy_for_chrome(proxy_url: str) -> Optional[str]:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∫—Å–∏ –¥–ª—è Chrome"""
    if not proxy_url:
        return None
    
    proxy = proxy_url.strip()
    if proxy.startswith('http://'):
        proxy = proxy[7:]
    elif proxy.startswith('https://'):
        proxy = proxy[8:]
    
    # Chrome –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç user:pass –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö
    if '@' in proxy:
        proxy = proxy.split('@')[-1]
    
    return proxy

# =========================
# –ú–ï–¢–û–î 1: –ü–†–û–°–¢–û–ô –ó–ê–ü–†–û–° (—Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ –∑–∞–π—Ç–∏)
# =========================

def _try_simple_request(url: str, use_proxy: bool = True) -> tuple[bool, str, Optional[str]]:
    """
    –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ –∑–∞–π—Ç–∏ –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (—É—Å–ø–µ—Ö, html, –æ—à–∏–±–∫–∞_–µ—Å–ª–∏_–µ—Å—Ç—å)
    """
    proxies = None
    if use_proxy and PROXY_URL:
        proxy_formatted = _format_proxy_for_requests(PROXY_URL)
        if proxy_formatted:
            proxies = {'http': proxy_formatted, 'https': proxy_formatted}
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
    
    try:
        logger.info(f"1. –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –∫ {url}")
        
        session = requests.Session()
        session.headers.update(BROWSER_HEADERS)
        
        # –î–ª—è HH.ru –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é –µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ
        if 'hh.ru' in url and not url.startswith('https://m.hh.ru'):
            if FORCE_MOBILE_HH:
                mobile_url = url.replace('https://hh.ru', 'https://m.hh.ru')
                logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é HH: {mobile_url}")
                url = mobile_url
        
        response = session.get(url, proxies=proxies, timeout=15, allow_redirects=True)
        
        logger.info(f"–°—Ç–∞—Ç—É—Å: {response.status_code}, —Ä–∞–∑–º–µ—Ä: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        html = response.text
        
        # –ï—Å–ª–∏ 200 –∏ –Ω–µ –∫–∞–ø—á–∞ - —É—Å–ø–µ—Ö
        if response.status_code == 200:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∞–ø—á—É
            html_lower = html.lower()
            has_captcha = any(x in html_lower for x in [
                'captcha', 'cloudflare', 'access denied', 
                'are you human', '–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç'
            ])
            
            if not has_captcha and len(html) > 500:
                logger.info(f"‚úÖ –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –£–°–ü–ï–®–ï–ù!")
                return True, html, None
            else:
                if has_captcha:
                    return False, html, "–ö–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞"
                else:
                    return False, html, "–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
        else:
            if response.status_code == 403:
                return False, html, "403 Forbidden"
            elif response.status_code == 429:
                return False, html, "429 Too Many Requests"
            else:
                return False, html, f"HTTP {response.status_code}"
                
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return False, "", str(e)

# =========================
# –ú–ï–¢–û–î 2: CLOUDSCRAPER (–µ—Å–ª–∏ –ø—Ä–æ—Å—Ç–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å)
# =========================

def _try_cloudscraper(url: str) -> tuple[bool, str, Optional[str]]:
    """–ü—Ä–æ–±—É–µ–º Cloudscraper –µ—Å–ª–∏ –ø—Ä–æ—Å—Ç–∞—è –ø–æ–ø—ã—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å"""
    if not CLOUDSCRAPER_ENABLED:
        return False, "", "Cloudscraper –æ—Ç–∫–ª—é—á–µ–Ω"
    
    try:
        import cloudscraper
        
        logger.info(f"2. –ü—Ä–æ–±—É–µ–º Cloudscraper –¥–ª—è {url}")
        
        scraper = cloudscraper.create_scraper(
            browser={'browser': 'chrome', 'platform': 'windows', 'mobile': False}
        )
        
        proxies = None
        if PROXY_URL:
            proxy_formatted = _format_proxy_for_requests(PROXY_URL)
            if proxy_formatted:
                proxies = {'http': proxy_formatted, 'https': proxy_formatted}
        
        response = scraper.get(url, headers=BROWSER_HEADERS, proxies=proxies, timeout=30)
        
        logger.info(f"Cloudscraper —Å—Ç–∞—Ç—É—Å: {response.status_code}")
        
        if response.status_code == 200:
            html = response.text
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∞–ø—á—É
            html_lower = html.lower()
            has_captcha = any(x in html_lower for x in [
                'captcha', 'cloudflare', 'access denied'
            ])
            
            if not has_captcha and len(html) > 500:
                logger.info(f"‚úÖ Cloudscraper –£–°–ü–ï–®–ï–ù!")
                return True, html, None
            else:
                return False, html, "–ö–∞–ø—á–∞ –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
        else:
            return False, response.text, f"HTTP {response.status_code}"
            
    except ImportError:
        logger.warning("Cloudscraper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False, "", "Cloudscraper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
    except Exception as e:
        logger.error(f"‚ùå Cloudscraper –æ—à–∏–±–∫–∞: {e}")
        return False, "", str(e)

# =========================
# –ú–ï–¢–û–î 3: UNDETECTED CHROMEDRIVER (–ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å)
# =========================

def _try_undetected_chromedriver(url: str) -> tuple[bool, str, Optional[str]]:
    """Undetected ChromeDriver –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç"""
    try:
        import undetected_chromedriver as uc
        
        logger.info(f"3. –ü—Ä–æ–±—É–µ–º Undetected ChromeDriver –¥–ª—è {url}")
        
        options = uc.ChromeOptions()
        
        if SELENIUM_HEADLESS:
            options.add_argument('--headless=new')
        
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument(f'--user-agent={BROWSER_HEADERS["User-Agent"]}')
        
        # –ü—Ä–æ–∫—Å–∏
        if PROXY_URL:
            proxy_formatted = _format_proxy_for_chrome(PROXY_URL)
            if proxy_formatted:
                options.add_argument(f'--proxy-server={proxy_formatted}')
        
        driver = uc.Chrome(options=options, version_main=120, suppress_welcome=True)
        
        try:
            # –°–∫—Ä—ã–≤–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é
            driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                "userAgent": BROWSER_HEADERS["User-Agent"]
            })
            
            driver.execute_script("""
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                });
            """)
            
            driver.get(url)
            time.sleep(random.uniform(3, 5))
            
            # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.5);")
            time.sleep(1)
            
            html = driver.page_source
            
            if len(html) < 500:
                return False, html, "–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∞–ø—á—É
            html_lower = html.lower()
            if any(x in html_lower for x in ['captcha', 'cloudflare', 'access denied']):
                return False, html, "–ö–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞"
            
            logger.info(f"‚úÖ Undetected ChromeDriver –£–°–ü–ï–®–ï–ù!")
            return True, html, None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ Undetected ChromeDriver: {e}")
            return False, "", str(e)
        finally:
            try:
                driver.quit()
            except:
                pass
                
    except ImportError:
        logger.warning("Undetected ChromeDriver –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False, "", "Undetected ChromeDriver –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
    except Exception as e:
        logger.error(f"‚ùå Undetected ChromeDriver –æ—à–∏–±–∫–∞: {e}")
        return False, "", str(e)

# =========================
# –ú–ï–¢–û–î 4: SELENIUM (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π)
# =========================

def _try_selenium(url: str) -> tuple[bool, str, Optional[str]]:
    """–í–∞—à —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π Selenium –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç"""
    if not SELENIUM_ENABLED:
        return False, "", "Selenium –æ—Ç–∫–ª—é—á–µ–Ω"
    
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        
        logger.info(f"4. –ü—Ä–æ–±—É–µ–º Selenium –¥–ª—è {url}")
        
        options = Options()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        
        if SELENIUM_HEADLESS:
            options.add_argument('--headless=new')
        
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument(f'--user-agent={BROWSER_HEADERS["User-Agent"]}')
        
        if PROXY_URL:
            proxy_for_selenium = _format_proxy_for_chrome(PROXY_URL)
            if proxy_for_selenium:
                options.add_argument(f'--proxy-server={proxy_for_selenium}')
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Render
        os.environ['WDM_LOG_LEVEL'] = '0'
        os.environ['WDM_LOCAL'] = '1'
        
        service = Service(
            ChromeDriverManager(
                cache_valid_range=30,
                path="/tmp/chromedriver"
            ).install()
        )
        
        driver = webdriver.Chrome(service=service, options=options)
        
        driver.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        )
        
        driver.get(url)
        time.sleep(random.uniform(3, 6))
        
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.5);")
        time.sleep(1)
        
        html = driver.page_source
        driver.quit()
        
        if len(html) < 500:
            return False, html, "–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
        
        html_lower = html.lower()
        if any(x in html_lower for x in ['captcha', 'cloudflare', 'access denied']):
            return False, html, "–ö–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞"
        
        logger.info(f"‚úÖ Selenium –£–°–ü–ï–®–ï–ù!")
        return True, html, None
        
    except Exception as e:
        logger.error(f"‚ùå Selenium –æ—à–∏–±–∫–∞: {e}")
        return False, "", str(e)

# =========================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –ü–ê–†–°–ò–ù–ì–ê
# =========================

def fetch_url_text_via_proxy(url: str) -> str:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ª–æ–≥–∏–∫–æ–π:
    1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ –∑–∞–π—Ç–∏
    2. –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å - Cloudscraper
    3. –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –ø—Ä–æ–±–ª–µ–º–∞ - Undetected ChromeDriver
    4. –ü–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å - Selenium
    """
    logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥: {url}")
    logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏: Cloudscraper={CLOUDSCRAPER_ENABLED}, Selenium={SELENIUM_ENABLED}")
    logger.info(f"PROXY_URL: {'–ï—Å—Ç—å' if PROXY_URL else '–ù–µ—Ç'}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º URL
    if not url or not looks_like_url(url):
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞")
    
    url = normalize_url(url)
    
    # –ú–µ—Ç–æ–¥—ã –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
    methods = [
        ("–ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å —Å –ø—Ä–æ–∫—Å–∏", lambda: _try_simple_request(url, use_proxy=True)),
        ("–ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏", lambda: _try_simple_request(url, use_proxy=False)),
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º Cloudscraper –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
    if CLOUDSCRAPER_ENABLED:
        methods.append(("Cloudscraper", lambda: _try_cloudscraper(url)))
    
    # –î–æ–±–∞–≤–ª—è–µ–º Undetected ChromeDriver
    methods.append(("Undetected ChromeDriver", lambda: _try_undetected_chromedriver(url)))
    
    # –î–æ–±–∞–≤–ª—è–µ–º Selenium –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
    if SELENIUM_ENABLED:
        methods.append(("Selenium", lambda: _try_selenium(url)))
    
    logger.info(f"–ë—É–¥–µ–º –ø—Ä–æ–±–æ–≤–∞—Ç—å {len(methods)} –º–µ—Ç–æ–¥–æ–≤")
    
    # –ü—Ä–æ–±—É–µ–º –≤—Å–µ –º–µ—Ç–æ–¥—ã
    last_error = None
    
    for method_name, method_func in methods:
        try:
            logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º {method_name}...")
            
            success, html, error = method_func()
            
            if success:
                text = html_to_text(html)
                logger.info(f"{method_name}: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞")
                
                if text and len(text) >= MIN_MEANINGFUL_TEXT_LENGTH:
                    logger.info(f"‚úÖ {method_name} –£–°–ü–ï–®–ï–ù!")
                    return text
                else:
                    logger.warning(f"‚ö†Ô∏è {method_name}: –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    continue
            else:
                logger.warning(f"‚ö†Ô∏è {method_name}: {error}")
                last_error = error
                continue
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è {method_name} –≤—ã–∑–≤–∞–ª –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
            last_error = e
            continue
    
    # –í—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏
    logger.error(f"‚ùå –í—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ –¥–ª—è {url}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    if 'hh.ru' in url:
        error_msg = (
            "HH.ru –∞–∫—Ç–∏–≤–Ω–æ –±–ª–æ–∫–∏—Ä—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã.\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞:\n"
            "1. –û—Ç–∫—Ä–æ–π—Ç–µ —Å—Å—ã–ª–∫—É –≤ –±—Ä–∞—É–∑–µ—Ä–µ\n"
            "2. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏\n" 
            "3. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –µ–≥–æ —Å—é–¥–∞"
        )
    elif last_error and ("403" in str(last_error) or "forbidden" in str(last_error).lower()):
        error_msg = "–°–∞–π—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –¥–æ—Å—Ç—É–ø (403 Forbidden). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Å—Å—ã–ª–∫—É –∏–ª–∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é."
    elif last_error and ("429" in str(last_error)):
        error_msg = "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ —Å–∞–π—Ç—É. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
    else:
        error_msg = GENERIC_VACANCY_ERROR_MSG
    
    raise ValueError(error_msg)
