import logging
import re
import time
import random
import os
import sys
from io import BytesIO
from typing import Optional, Dict, Any, Tuple
from urllib.parse import urlparse

import requests
from bs4 import BeautifulSoup
from PyPDF2 import PdfReader

from config import (
    PROXY_URL, 
    MIN_MEANINGFUL_TEXT_LENGTH,
    SELENIUM_ENABLED,
    SELENIUM_TIMEOUT,
    SELENIUM_HEADLESS
)

logger = logging.getLogger(__name__)

GENERIC_VACANCY_ERROR_MSG = (
    "–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å–∞–π—Ç–∞.\n"
    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –≤—Ä—É—á–Ω—É—é."
)

# =========================
# –ü–ï–†–ï–ú–ï–ù–ù–´–ï –ò–ó ENVIRONMENT
# =========================

CLOUDSCRAPER_ENABLED = os.getenv("CLOUDSCRAPER_ENABLED", "true").lower() == "true"
FORCE_MOBILE_HH = os.getenv("FORCE_MOBILE_HH", "true").lower() == "true"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –º–æ–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
RETRY_COUNT = int(os.getenv("RETRY_COUNT", "3"))

# –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ headers —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ User-Agent
BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
    "Accept-Encoding": "gzip, deflate, br",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
    "Sec-Fetch-Dest": "document",
    "Sec-Fetch-Mode": "navigate",
    "Sec-Fetch-Site": "none",
    "Sec-Fetch-User": "?1",
    "Cache-Control": "max-age=0",
    "Sec-Ch-Ua": '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
    "Sec-Ch-Ua-Mobile": "?0",
    "Sec-Ch-Ua-Platform": '"Windows"',
}

# Mobile headers –¥–ª—è HH.ru
MOBILE_HEADERS = {
    "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "ru-RU,ru;q=0.9",
    "Accept-Encoding": "gzip, deflate, br",
}

# =========================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# =========================

def clean_text(raw: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
    if not raw:
        return ""
    text = raw.replace("\r\n", "\n").replace("\r", "\n")
    lines = [line.strip() for line in text.split("\n")]
    text = "\n".join(lines)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

def extract_text_from_pdf_bytes(data: bytes) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
    try:
        reader = PdfReader(BytesIO(data))
        pages_text = []

        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                pages_text.append(page_text)

        text = "\n\n".join(pages_text)
        text = clean_text(text)

        if not text or len(text) < 50:
            raise ValueError("PDF —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Ç–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")

        logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ PDF")
        return text

    except ValueError:
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {e}", exc_info=True)
        raise ValueError(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å PDF —Ñ–∞–π–ª. "
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç."
        )

def looks_like_url(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ URL"""
    if not text:
        return False
    text = text.strip()
    URL_REGEX = re.compile(r"^(https?://)?([a-z0-9.-]+\.[a-z]{2,})(/.*)?$", re.IGNORECASE)
    return bool(URL_REGEX.match(text))

def normalize_url(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL"""
    text = text.strip()
    if not text.startswith(("http://", "https://")):
        return "https://" + text
    return text

def html_to_text(html: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML"""
    if not html:
        return ""
    
    try:
        soup = BeautifulSoup(html, "html.parser")
        
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for element in soup(["script", "style", "nav", "footer", "header", "aside", "form", "iframe", "button", "input", "select", "textarea"]):
            element.decompose()
        
        # –î–ª—è HH.ru —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ
        if 'hh.ru' in html.lower():
            for element in soup.find_all(['div', 'section'], class_=re.compile(r'(bloko-column|vacancy-serp-item|sidebar|related|similar)')):
                element.decompose()
        
        text = soup.get_text(separator='\n', strip=True)
        text = clean_text(text)
        
        # –£–¥–∞–ª—è–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
        lines = [line for line in text.split('\n') if len(line.strip()) > 5]
        text = '\n'.join(lines)
        
        return text
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
        return ""

# =========================
# –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ö–°–ò
# =========================

def _format_proxy_for_requests(proxy_url: str) -> Optional[Dict[str, str]]:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∫—Å–∏ –¥–ª—è requests"""
    if not proxy_url:
        return None
    
    proxy = proxy_url.strip()
    
    # –£–∂–µ –µ—Å—Ç—å —Å—Ö–µ–º–∞
    if proxy.startswith(('http://', 'https://', 'socks5://')):
        return {
            'http': proxy,
            'https': proxy
        }
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ö–µ–º—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if not proxy.startswith('http'):
        proxy = f"http://{proxy}"
    
    return {
        'http': proxy,
        'https': proxy
    }

def _format_proxy_for_chrome(proxy_url: str) -> Optional[str]:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–∫—Å–∏ –¥–ª—è Chrome"""
    if not proxy_url:
        return None
    
    proxy = proxy_url.strip()
    
    # –£–¥–∞–ª—è–µ–º —Å—Ö–µ–º—É –¥–ª—è Chrome
    if proxy.startswith('http://'):
        proxy = proxy[7:]
    elif proxy.startswith('https://'):
        proxy = proxy[8:]
    elif proxy.startswith('socks5://'):
        proxy = proxy[9:]
    
    # Chrome –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç user:pass –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö
    if '@' in proxy:
        proxy = proxy.split('@')[-1]
    
    return proxy

# =========================
# –ú–ï–¢–û–î 1: –ü–†–û–°–¢–û–ô –ó–ê–ü–†–û–° —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ headers
# =========================

def _try_simple_request(url: str, use_proxy: bool = True, force_mobile: bool = False) -> Tuple[bool, str, Optional[str]]:
    """
    –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ –∑–∞–π—Ç–∏ –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä
    """
    proxies = None
    if use_proxy and PROXY_URL:
        proxies = _format_proxy_for_requests(PROXY_URL)
        if proxies:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞")
    
    try:
        logger.info(f"1. –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –∫ {url}")
        
        session = requests.Session()
        
        # –í—ã–±–∏—Ä–∞–µ–º headers
        if 'hh.ru' in url and force_mobile:
            headers = MOBILE_HEADERS
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º URL –≤ –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é
            url = url.replace('https://hh.ru', 'https://m.hh.ru')
            url = url.replace('http://hh.ru', 'http://m.hh.ru')
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é HH: {url}")
        else:
            headers = BROWSER_HEADERS
        
        session.headers.update(headers)
        
        # –î–æ–±–∞–≤–ª—è–µ–º cookies
        session.cookies.update({
            'accept': '1',
            'force_cookie_consent': 'true',
        })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        time.sleep(random.uniform(1, 3))
        
        response = session.get(
            url, 
            proxies=proxies, 
            timeout=20, 
            allow_redirects=True,
            verify=False  # –ú–æ–∂–µ—Ç –ø–æ–º–æ—á—å —Å –Ω–µ–∫–æ—Ç–æ—Ä—ã–º–∏ SSL –æ—à–∏–±–∫–∞–º–∏
        )
        
        logger.info(f"–°—Ç–∞—Ç—É—Å: {response.status_code}, —Ä–∞–∑–º–µ—Ä: {len(response.text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        html = response.text
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∞–ø—á—É –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        html_lower = html.lower()
        has_captcha = any(x in html_lower for x in [
            'captcha', 'cloudflare', 'access denied', 
            'are you human', '–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç',
            'ddos-guard', 'recaptcha', 'hcaptcha'
        ])
        
        if response.status_code == 200 and not has_captcha and len(html) > 1000:
            logger.info(f"‚úÖ –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –£–°–ü–ï–®–ï–ù!")
            return True, html, None
        else:
            if has_captcha:
                return False, html, "–ö–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞"
            elif response.status_code == 403:
                return False, html, "403 Forbidden"
            elif response.status_code == 429:
                return False, html, "429 Too Many Requests"
            elif len(html) < 500:
                return False, html, "–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
            else:
                return False, html, f"HTTP {response.status_code}"
                
    except requests.exceptions.SSLError:
        # –ü—Ä–æ–±—É–µ–º –±–µ–∑ SSL –ø—Ä–æ–≤–µ—Ä–∫–∏
        try:
            session = requests.Session()
            session.headers.update(BROWSER_HEADERS)
            response = session.get(url, timeout=20, verify=False)
            if response.status_code == 200:
                return True, response.text, None
            return False, response.text, f"HTTP {response.status_code}"
        except Exception as e:
            return False, "", f"SSL Error: {e}"
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return False, "", str(e)

# =========================
# –ú–ï–¢–û–î 2: CLOUDSCRAPER —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏
# =========================

def _try_cloudscraper(url: str) -> Tuple[bool, str, Optional[str]]:
    """–ü—Ä–æ–±—É–µ–º Cloudscraper"""
    if not CLOUDSCRAPER_ENABLED:
        return False, "", "Cloudscraper –æ—Ç–∫–ª—é—á–µ–Ω"
    
    try:
        import cloudscraper
        
        logger.info(f"2. –ü—Ä–æ–±—É–µ–º Cloudscraper –¥–ª—è {url}")
        
        # –°–æ–∑–¥–∞–µ–º scraper —Å —Ä–∞–∑–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        scraper = cloudscraper.create_scraper(
            browser={
                'browser': 'chrome',
                'platform': 'windows',
                'mobile': False,
                'desktop': True
            },
            delay=10,
            interpreter='nodejs'
        )
        
        proxies = None
        if PROXY_URL:
            proxies = _format_proxy_for_requests(PROXY_URL)
        
        # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑
        for attempt in range(2):
            try:
                response = scraper.get(
                    url, 
                    headers=BROWSER_HEADERS, 
                    proxies=proxies, 
                    timeout=30
                )
                
                logger.info(f"Cloudscraper —Å—Ç–∞—Ç—É—Å: {response.status_code}")
                
                if response.status_code == 200:
                    html = response.text
                    
                    if len(html) > 1000 and 'captcha' not in html.lower():
                        logger.info(f"‚úÖ Cloudscraper –£–°–ü–ï–®–ï–ù!")
                        return True, html, None
                    else:
                        if attempt == 0:
                            # –ñ–¥–µ–º –∏ –ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑
                            time.sleep(random.uniform(5, 10))
                            continue
                        else:
                            return False, html, "–ö–∞–ø—á–∞ –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
                else:
                    return False, response.text, f"HTTP {response.status_code}"
                    
            except Exception as e:
                if attempt == 0:
                    time.sleep(5)
                    continue
                raise
                
        return False, "", "Cloudscraper –Ω–µ —Å–º–æ–≥ –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"
            
    except ImportError:
        logger.warning("Cloudscraper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False, "", "Cloudscraper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
    except Exception as e:
        logger.error(f"‚ùå Cloudscraper –æ—à–∏–±–∫–∞: {e}")
        return False, "", str(e)

# =========================
# –ú–ï–¢–û–î 3: UNDETECTED CHROMEDRIVER —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏
# =========================

def _try_undetected_chromedriver(url: str) -> Tuple[bool, str, Optional[str]]:
    """Undetected ChromeDriver —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º stealth"""
    try:
        import undetected_chromedriver as uc
        
        logger.info(f"3. –ü—Ä–æ–±—É–µ–º Undetected ChromeDriver –¥–ª—è {url}")
        
        options = uc.ChromeOptions()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Render
        if os.environ.get('RENDER', ''):
            options.binary_location = '/usr/bin/google-chrome'
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            SELENIUM_HEADLESS = True  # –ù–∞ Render –≤—Å–µ–≥–¥–∞ headless
        
        if SELENIUM_HEADLESS:
            options.add_argument('--headless=new')
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ stealth –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('--disable-features=IsolateOrigins,site-per-process')
        options.add_argument('--disable-web-security')
        options.add_argument('--disable-site-isolation-trials')
        options.add_argument('--disable-logging')
        options.add_argument('--log-level=3')
        options.add_argument('--output=/dev/null')
        options.add_argument('--disable-3d-apis')
        options.add_argument('--disable-background-timer-throttling')
        options.add_argument('--disable-backgrounding-occluded-windows')
        options.add_argument('--disable-renderer-backgrounding')
        options.add_argument('--disable-features=AudioServiceOutOfProcess')
        
        # –ü—Ä–æ–∫—Å–∏
        if PROXY_URL:
            proxy_formatted = _format_proxy_for_chrome(PROXY_URL)
            if proxy_formatted:
                options.add_argument(f'--proxy-server={proxy_formatted}')
        
        # –í–µ—Ä—Å–∏—è Chrome
        chrome_version = 131  # –ê–∫—Ç—É–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
        
        try:
            driver = uc.Chrome(
                options=options,
                version_main=chrome_version,
                suppress_welcome=True,
                driver_executable_path='/tmp/chromedriver' if os.environ.get('RENDER') else None
            )
            
            try:
                # –£–ª—É—á—à–µ–Ω–Ω—ã–π stealth
                driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
                driver.execute_script("Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]})")
                driver.execute_script("Object.defineProperty(navigator, 'languages', {get: () => ['ru-RU', 'ru', 'en-US', 'en']})")
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º User-Agent
                driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                    "userAgent": BROWSER_HEADERS["User-Agent"],
                    "platform": "Windows"
                })
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º cookies –ø–µ—Ä–µ–¥ –∑–∞—Ö–æ–¥–æ–º
                driver.get("https://google.com")
                time.sleep(1)
                
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Ü–µ–ª–µ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                driver.get(url)
                
                # –ò–º–∏—Ç–∞—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞
                time.sleep(random.uniform(2, 4))
                
                # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞
                scroll_height = driver.execute_script("return document.body.scrollHeight")
                for i in range(0, scroll_height, random.randint(200, 400)):
                    driver.execute_script(f"window.scrollTo(0, {i});")
                    time.sleep(random.uniform(0.1, 0.3))
                
                time.sleep(random.uniform(1, 2))
                
                # –ü–æ–ª—É—á–∞–µ–º HTML
                html = driver.page_source
                
                if len(html) < 1000:
                    return False, html, "–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–∞–ø—á—É
                html_lower = html.lower()
                if any(x in html_lower for x in ['captcha', 'cloudflare', 'access denied', 'ddos-guard']):
                    return False, html, "–ö–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞"
                
                logger.info(f"‚úÖ Undetected ChromeDriver –£–°–ü–ï–®–ï–ù!")
                return True, html, None
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ Undetected ChromeDriver: {e}")
                return False, "", str(e)
            finally:
                try:
                    driver.quit()
                except:
                    pass
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            return False, "", str(e)
                
    except ImportError:
        logger.warning("Undetected ChromeDriver –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return False, "", "Undetected ChromeDriver –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω"
    except Exception as e:
        logger.error(f"‚ùå Undetected ChromeDriver –æ—à–∏–±–∫–∞: {e}")
        return False, "", str(e)

# =========================
# –ú–ï–¢–û–î 4: SELENIUM —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –æ—à–∏–±–∫–æ–π
# =========================

def _try_selenium(url: str) -> Tuple[bool, str, Optional[str]]:
    """Selenium —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º webdriver-manager"""
    if not SELENIUM_ENABLED:
        return False, "", "Selenium –æ—Ç–∫–ª—é—á–µ–Ω"
    
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.chrome.service import Service
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ
        from webdriver_manager.chrome import ChromeDriverManager
        from webdriver_manager.core.os_manager import ChromeType
        
        logger.info(f"4. –ü—Ä–æ–±—É–µ–º Selenium –¥–ª—è {url}")
        
        options = Options()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Render
        if os.environ.get('RENDER', ''):
            options.binary_location = '/usr/bin/google-chrome'
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            SELENIUM_HEADLESS = True
        
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument(f'--user-agent={BROWSER_HEADERS["User-Agent"]}')
        
        if SELENIUM_HEADLESS:
            options.add_argument('--headless=new')
        
        if PROXY_URL:
            proxy_for_selenium = _format_proxy_for_chrome(PROXY_URL)
            if proxy_for_selenium:
                options.add_argument(f'--proxy-server={proxy_for_selenium}')
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Render
        chrome_driver_path = None
        
        if os.environ.get('RENDER'):
            # –ù–∞ Render –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π chromedriver
            chrome_driver_path = '/usr/local/bin/chromedriver'
            service = Service(chrome_driver_path)
        else:
            # –õ–æ–∫–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä
            os.environ['WDM_LOG_LEVEL'] = '0'
            os.environ['WDM_LOCAL'] = '1'
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –û–®–ò–ë–ö–ò: —É–±–∏—Ä–∞–µ–º –Ω–µ–≤–µ—Ä–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            driver_manager = ChromeDriverManager()
            chrome_driver_path = driver_manager.install()
            service = Service(chrome_driver_path)
        
        driver = webdriver.Chrome(service=service, options=options)
        
        # Stealth —Å–∫—Ä–∏–ø—Ç—ã
        stealth_script = """
        // Overwrite the `languages` property to use a custom getter.
        Object.defineProperty(navigator, 'languages', {
          get: () => ['ru-RU', 'ru', 'en-US', 'en'],
        });
        
        // Overwrite the `plugins` property to use a custom getter.
        Object.defineProperty(navigator, 'plugins', {
          get: () => [1, 2, 3, 4, 5],
        });
        
        // Pass the Webdriver test
        Object.defineProperty(navigator, 'webdriver', {
          get: () => undefined,
        });
        
        // Pass the Chrome test.
        window.chrome = {
          runtime: {},
        };
        
        // Pass the Permissions test.
        const originalQuery = window.navigator.permissions.query;
        window.navigator.permissions.query = (parameters) => (
          parameters.name === 'notifications' ?
            Promise.resolve({ state: Notification.permission }) :
            originalQuery(parameters)
        );
        """
        
        driver.execute_script(stealth_script)
        
        # –î–æ–±–∞–≤–ª—è–µ–º cookies
        driver.get("https://google.com")
        time.sleep(1)
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å
        driver.get(url)
        time.sleep(random.uniform(3, 6))
        
        # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.5);")
        time.sleep(1)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.8);")
        time.sleep(1)
        
        html = driver.page_source
        driver.quit()
        
        if len(html) < 1000:
            return False, html, "–ö–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
        
        html_lower = html.lower()
        if any(x in html_lower for x in ['captcha', 'cloudflare', 'access denied']):
            return False, html, "–ö–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞"
        
        logger.info(f"‚úÖ Selenium –£–°–ü–ï–®–ï–ù!")
        return True, html, None
        
    except Exception as e:
        logger.error(f"‚ùå Selenium –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        return False, "", str(e)

# =========================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –ü–ê–†–°–ò–ù–ì–ê
# =========================

def fetch_url_text_via_proxy(url: str) -> str:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
    """
    logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥: {url}")
    logger.info(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∏: Cloudscraper={CLOUDSCRAPER_ENABLED}, Selenium={SELENIUM_ENABLED}")
    logger.info(f"PROXY_URL: {'–ï—Å—Ç—å' if PROXY_URL else '–ù–µ—Ç'}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º URL
    if not url or not looks_like_url(url):
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞")
    
    url = normalize_url(url)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –º–µ—Ç–æ–¥–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∞–π—Ç–∞
    is_hh = 'hh.ru' in url
    
    # –î–ª—è HH.ru –ø—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é
    if is_hh and FORCE_MOBILE_HH and not url.startswith('https://m.hh.ru'):
        mobile_url = url.replace('https://hh.ru', 'https://m.hh.ru')
        logger.info(f"–ü—Ä–æ–±—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é: {mobile_url}")
        
        # –ü—Ä–æ–±—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é
        success, html, error = _try_simple_request(mobile_url, force_mobile=True)
        if success:
            text = html_to_text(html)
            if text and len(text) >= MIN_MEANINGFUL_TEXT_LENGTH:
                return text
    
    # –ú–µ—Ç–æ–¥—ã –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
    methods = [
        ("–ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å (–¥–µ—Å–∫—Ç–æ–ø)", lambda: _try_simple_request(url, use_proxy=True, force_mobile=False)),
        ("–ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å (–º–æ–±–∏–ª—å–Ω—ã–π)", lambda: _try_simple_request(url, use_proxy=True, force_mobile=True)),
        ("–ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ –ø—Ä–æ–∫—Å–∏", lambda: _try_simple_request(url, use_proxy=False, force_mobile=False)),
    ]
    
    if CLOUDSCRAPER_ENABLED:
        methods.append(("Cloudscraper", lambda: _try_cloudscraper(url)))
    
    methods.append(("Undetected ChromeDriver", lambda: _try_undetected_chromedriver(url)))
    
    if SELENIUM_ENABLED:
        methods.append(("Selenium", lambda: _try_selenium(url)))
    
    logger.info(f"–ë—É–¥–µ–º –ø—Ä–æ–±–æ–≤–∞—Ç—å {len(methods)} –º–µ—Ç–æ–¥–æ–≤")
    
    # –ü—Ä–æ–±—É–µ–º –≤—Å–µ –º–µ—Ç–æ–¥—ã
    last_error = None
    
    for method_name, method_func in methods:
        try:
            logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º {method_name}...")
            
            success, html, error = method_func()
            
            if success:
                text = html_to_text(html)
                logger.info(f"{method_name}: –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞")
                
                if text and len(text) >= MIN_MEANINGFUL_TEXT_LENGTH:
                    logger.info(f"‚úÖ {method_name} –£–°–ü–ï–®–ï–ù!")
                    return text
                else:
                    logger.warning(f"‚ö†Ô∏è {method_name}: –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
                    continue
            else:
                logger.warning(f"‚ö†Ô∏è {method_name}: {error}")
                last_error = error
                continue
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è {method_name} –≤—ã–∑–≤–∞–ª –∏—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
            last_error = e
            continue
    
    # –í—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏
    logger.error(f"‚ùå –í—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ –¥–ª—è {url}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    if 'hh.ru' in url:
        error_msg = (
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞,—Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏"
        )
    elif last_error and ("403" in str(last_error)):
        error_msg = "–°–∞–π—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª –¥–æ—Å—Ç—É–ø (403 Forbidden). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Å—Å—ã–ª–∫—É –∏–ª–∏ —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é."
    elif last_error and ("429" in str(last_error)):
        error_msg = "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏—Ç–µ 5 –º–∏–Ω—É—Ç –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
    else:
        error_msg = GENERIC_VACANCY_ERROR_MSG
    
    raise ValueError(error_msg)
