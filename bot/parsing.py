import logging
import re
import time
import random
import os
from io import BytesIO
from typing import Optional

import requests
from bs4 import BeautifulSoup
from PyPDF2 import PdfReader

from config import (
    PROXY_URL, 
    MIN_MEANINGFUL_TEXT_LENGTH,
    SELENIUM_ENABLED,
    SELENIUM_TIMEOUT,
    SELENIUM_HEADLESS
)

logger = logging.getLogger(__name__)

# –ï–¥–∏–Ω–æ–µ "—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ" —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –∫–æ–≥–¥–∞ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–∞–∫–∞–Ω—Å–∏—é –ø–æ —Å—Å—ã–ª–∫–µ
GENERIC_VACANCY_ERROR_MSG = (
    "–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å–∞–π—Ç–∞.\n"
    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –≤—Ä—É—á–Ω—É—é."
)

# =========================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# =========================

def clean_text(raw: str) -> str:
    if not raw:
        return ""
    text = raw.replace("\r\n", "\n").replace("\r", "\n")
    lines = [line.strip() for line in text.split("\n")]
    text = "\n".join(lines)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

# =========================
# PDF –ü–ê–†–°–ï–†
# =========================

def extract_text_from_pdf_bytes(data: bytes) -> str:
    try:
        reader = PdfReader(BytesIO(data))
        pages_text = []

        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                pages_text.append(page_text)

        text = "\n\n".join(pages_text)
        text = clean_text(text)

        if not text or len(text) < 50:
            raise ValueError("PDF —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Ç–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")

        logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ PDF")
        return text

    except ValueError:
        # —É–∂–µ "—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è" –æ—à–∏–±–∫–∞
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {e}", exc_info=True)
        raise ValueError(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å PDF —Ñ–∞–π–ª. "
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç."
        )

# =========================
# –õ–û–ì–ò–ö–ê –†–ê–ë–û–¢–´ –°–û –°–°–´–õ–ö–ê–ú–ò
# =========================

URL_REGEX = re.compile(
    r"^(https?://)?([a-z0-9.-]+\.[a-z]{2,})(/.*)?$",
    re.IGNORECASE,
)

def looks_like_url(text: str) -> bool:
    if not text:
        return False
    text = text.strip()
    return bool(URL_REGEX.match(text))

def normalize_url(text: str) -> str:
    text = text.strip()
    if not text.startswith(("http://", "https://")):
        return "https://" + text
    return text

def html_to_text(html: str) -> str:
    try:
        soup = BeautifulSoup(html, "html.parser")
        for element in soup(["script", "style", "nav", "footer", "header", "aside"]):
            element.decompose()
        text = soup.get_text(separator="\n")
        return clean_text(text)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML: {e}", exc_info=True)
        return ""

# =========================
# SELENIUM –î–õ–Ø RENDER
# =========================

def init_selenium_driver(proxy_url: Optional[str] = None):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Selenium –Ω–∞ Render"""
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        
        options = Options()
        
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û –¥–ª—è Render!
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        
        if SELENIUM_HEADLESS:
            options.add_argument('--headless=new')
        
        # –û–±—Ö–æ–¥ –¥–µ—Ç–µ–∫—Ç–∞
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        # User-Agent
        options.add_argument(
            '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
            'AppleWebKit/537.36 (KHTML, like Gecko) '
            'Chrome/120.0.0.0 Safari/537.36'
        )
        
        # –ü—Ä–æ–∫—Å–∏ –¥–ª—è Selenium
        if proxy_url:
            # –£–±–∏—Ä–∞–µ–º —Å—Ö–µ–º—É –∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è Selenium
            proxy_for_selenium = proxy_url
            if proxy_for_selenium.startswith('http://'):
                proxy_for_selenium = proxy_for_selenium[7:]
            if '@' in proxy_for_selenium:
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ host:port
                proxy_for_selenium = proxy_for_selenium.split('@')[1]
            options.add_argument(f'--proxy-server={proxy_for_selenium}')
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è Selenium: {proxy_for_selenium}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è webdriver-manager
        os.environ['WDM_LOG_LEVEL'] = '0'  # –º–µ–Ω—å—à–µ –ª–æ–≥–æ–≤
        os.environ['WDM_LOCAL'] = '1'      # –∫—ç—à
        
        service = Service(
            ChromeDriverManager(
                cache_valid_range=30,
                path="/tmp/chromedriver"
            ).install()
        )
        
        options.add_argument('--disable-software-rasterizer')
        options.add_argument('--disable-logging')
        options.add_argument('--log-level=3')
        options.add_argument('--silent')
        
        driver = webdriver.Chrome(service=service, options=options)
        
        # –°–∫—Ä—ã–≤–∞–µ–º —Ñ–ª–∞–≥ webdriver
        driver.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
        )
        
        return driver
        
    except ImportError as e:
        logger.error(f"‚ùå Selenium –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
        raise ImportError("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install selenium webdriver-manager")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Selenium: {e}", exc_info=True)
        raise

def parse_with_selenium(url: str, proxy_url: Optional[str] = None) -> str:
    """–ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Selenium"""
    if not SELENIUM_ENABLED:
        # –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω–µ –≥–æ–≤–æ—Ä–∏–º –ø—Ä–æ Selenium, –ø—Ä–æ—Å—Ç–æ –æ–±—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)
    
    driver = None
    try:
        logger.info(f"ü¶ä Selenium: –ø–∞—Ä—Å–∏–º {url}")
        start_time = time.time()
        
        driver = init_selenium_driver(proxy_url)
        
        driver.get(url)
        
        # –ñ–¥—ë–º –∑–∞–≥—Ä—É–∑–∫—É
        wait_time = random.uniform(3, 6)
        time.sleep(wait_time)
        
        # –°–∫—Ä–æ–ª–ª–∏–º –≤–Ω–∏–∑
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.5);")
        time.sleep(random.uniform(1, 2))
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(random.uniform(1, 2))
        
        html = driver.page_source
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∞–ø—á—É
        if detect_captcha(html):
            logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ (Selenium)")
            raise ValueError(GENERIC_VACANCY_ERROR_MSG)
        
        elapsed = time.time() - start_time
        logger.info(f"‚úÖ Selenium: —É—Å–ø–µ—à–Ω–æ –∑–∞ {elapsed:.1f} —Å–µ–∫, {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return html
        
    except Exception as e:
        logger.error(f"‚ùå Selenium –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –¥–∞—ë–º –æ–±—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)
    finally:
        if driver:
            try:
                driver.quit()
            except Exception:
                pass

def detect_captcha(html: str) -> bool:
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫–∞–ø—á–∏"""
    if not html:
        return True
    
    html_lower = html.lower()
    captcha_indicators = [
        "captcha",
        "cloudflare",
        "are you human",
        "access denied",
        "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç",
    ]
    
    return any(indicator in html_lower for indicator in captcha_indicators)

# =========================
# REQUESTS FALLBACK
# =========================

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Accept-Language": "ru-RU,ru;q=0.9",
}

def _normalize_proxy_url(raw: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏ –¥–ª—è requests"""
    raw = (raw or "").strip()
    if not raw:
        return raw

    # –£–∂–µ –µ—Å—Ç—å —Å—Ö–µ–º–∞ (http://, socks5:// –∏ —Ç.–ø.)
    if re.match(r"^[a-zA-Z0-9+.-]+://", raw):
        return raw

    # –§–æ—Ä–º–∞—Ç—ã –≤–∏–¥–∞ host:port@user:pass –∏–ª–∏ user:pass@host:port
    if "@" in raw:
        left, right = raw.split("@", 1)
        
        def looks_like_host_port(part: str) -> bool:
            host, _, _ = part.partition(":")
            return "." in host and re.search(r"[a-zA-Z]", host) is not None

        if looks_like_host_port(left):
            host_port = left
            creds = right
        else:
            creds = left
            host_port = right

        return f"http://{creds}@{host_port}"

    # –ü—Ä–æ—Å—Ç–æ host:port
    return f"http://{raw}"

def fetch_html_via_requests(url: str, proxy_url: Optional[str] = None) -> str:
    """–ó–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ requests"""
    proxies = None
    if proxy_url:
        normalized_proxy = _normalize_proxy_url(proxy_url)
        proxies = {"http": normalized_proxy, "https": normalized_proxy}
        logger.info(f"üîó Requests —Å –ø—Ä–æ–∫—Å–∏: {normalized_proxy}")

    try:
        logger.info(f"üåê Requests: –ø–∞—Ä—Å–∏–º {url}")
        
        session = requests.Session()
        session.headers.update(HEADERS)
        
        resp = session.get(url, proxies=proxies, timeout=20)
        resp.raise_for_status()

        html = resp.text

        if detect_captcha(html):
            logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ (Requests)")
            raise ValueError(GENERIC_VACANCY_ERROR_MSG)

        if len(html) < 500:
            logger.warning(f"‚ö†Ô∏è –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç ({len(html)} —Å–∏–º–≤–æ–ª–æ–≤)")
            raise ValueError(GENERIC_VACANCY_ERROR_MSG)

        return html

    except requests.exceptions.Timeout:
        logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ", exc_info=True)
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)
    except requests.RequestException as e:
        logger.error(f"‚ùå HTTP –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}", exc_info=True)
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)
    except Exception as e:
        logger.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ requests: {e}", exc_info=True)
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)

# =========================
# –£–ú–ù–´–ô –ü–ê–†–°–ï–† –° –§–û–õ–ë–≠–ö–ê–ú–ò
# =========================

def fetch_url_text_via_proxy(url: str) -> str:
    """
    –£–º–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏.
    –ù–∞ Render —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º requests, –ø–æ—Ç–æ–º Selenium, –ø–æ—Ç–æ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏.
    """
    methods_to_try = []
    
    # 1. Requests + –ø—Ä–æ–∫—Å–∏
    if PROXY_URL:
        methods_to_try.append(
            ("Requests —Å –ø—Ä–æ–∫—Å–∏", lambda: fetch_html_via_requests(url, PROXY_URL))
        )
    
    # 2. Selenium + –ø—Ä–æ–∫—Å–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)
    if SELENIUM_ENABLED and PROXY_URL:
        methods_to_try.append(
            ("Selenium —Å –ø—Ä–æ–∫—Å–∏", lambda: parse_with_selenium(url, PROXY_URL))
        )
    
    # 3. Requests –±–µ–∑ –ø—Ä–æ–∫—Å–∏
    methods_to_try.append(
        ("Requests –±–µ–∑ –ø—Ä–æ–∫—Å–∏", lambda: fetch_html_via_requests(url, None))
    )
    
    last_error: Optional[Exception] = None

    for method_name, parser_func in methods_to_try:
        try:
            logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º {method_name} –¥–ª—è {url}")
            html = parser_func()
            text = html_to_text(html)
            
            if text and len(text) >= MIN_MEANINGFUL_TEXT_LENGTH:
                logger.info(f"‚úÖ {method_name} —É—Å–ø–µ—à–µ–Ω: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                return text
            else:
                logger.warning(
                    f"‚ö†Ô∏è {method_name}: –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ ({len(text) if text else 0} —Å–∏–º–≤–æ–ª–æ–≤)"
                )
                last_error = ValueError(GENERIC_VACANCY_ERROR_MSG)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è {method_name} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
            last_error = e
            continue
    
    # –í—Å—ë —É–ø–∞–ª–æ ‚Üí –µ–¥–∏–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    raise ValueError(GENERIC_VACANCY_ERROR_MSG)
