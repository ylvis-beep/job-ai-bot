import logging
import re
import time
import random
from io import BytesIO
from typing import Optional, Tuple

import requests
from bs4 import BeautifulSoup
from PyPDF2 import PdfReader

from config import (
    PROXY_URL, 
    MIN_MEANINGFUL_TEXT_LENGTH,
    SELENIUM_ENABLED,
    SELENIUM_TIMEOUT,
    SELENIUM_HEADLESS
)

logger = logging.getLogger(__name__)

# –ï–¥–∏–Ω–æ–µ "—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ" —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
GENERIC_VACANCY_ERROR_MSG = (
    "–ù–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å–∞–π—Ç–∞.\n"
    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–∫–æ–ø–∏—Ä—É–π—Ç–µ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –≤—Ä—É—á–Ω—É—é."
)

# =========================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –¢–ï–ö–°–¢–ê
# =========================

def clean_text(raw: str) -> str:
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞: —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏."""
    if not raw:
        return ""

    text = raw.replace("\r\n", "\n").replace("\r", "\n")
    lines = [line.strip() for line in text.split("\n")]
    text = "\n".join(lines)
    text = re.sub(r"\n{3,}", "\n\n", text)

    return text.strip()

# =========================
# PDF –ü–ê–†–°–ï–†
# =========================

def extract_text_from_pdf_bytes(data: bytes) -> str:
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —Ñ–∞–π–ª–∞.
    """
    try:
        reader = PdfReader(BytesIO(data))
        pages_text = []

        for page in reader.pages:
            page_text = page.extract_text()
            if page_text:
                pages_text.append(page_text)

        text = "\n\n".join(pages_text)
        text = clean_text(text)

        if not text or len(text) < 50:
            raise ValueError("PDF —Ñ–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Ç–∞–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞")

        logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ PDF")
        return text

    except ValueError:
        raise

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF: {e}", exc_info=True)
        raise ValueError(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å PDF —Ñ–∞–π–ª. "
            "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç."
        )

# =========================
# –õ–û–ì–ò–ö–ê –†–ê–ë–û–¢–´ –°–û –°–°–´–õ–ö–ê–ú–ò
# =========================

URL_REGEX = re.compile(
    r"^(https?://)?([a-z0-9.-]+\.[a-z]{2,})(/.*)?$",
    re.IGNORECASE,
)

def looks_like_url(text: str) -> bool:
    """–ú—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ‚Äì –ø–æ—Ö–æ–∂–µ –ª–∏ –Ω–∞ URL."""
    if not text:
        return False
    text = text.strip()
    return bool(URL_REGEX.match(text))

def normalize_url(text: str) -> str:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ URL –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http/https."""
    text = text.strip()
    if not text.startswith(("http://", "https://")):
        return "https://" + text
    return text

def html_to_text(html: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML."""
    try:
        soup = BeautifulSoup(html, "html.parser")

        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for element in soup(["script", "style", "nav", "footer", "header", "aside"]):
            element.decompose()

        text = soup.get_text(separator="\n")
        return clean_text(text)

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML: {e}", exc_info=True)
        return ""

# =========================
# SELENIUM –ü–ê–†–°–ï–† (–û–°–ù–û–í–ù–û–ô)
# =========================

def init_selenium_driver(proxy_url: Optional[str] = None):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Selenium –¥—Ä–∞–π–≤–µ—Ä–∞ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –ø—Ä–æ–∫—Å–∏."""
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.chrome.service import Service
        from webdriver_manager.chrome import ChromeDriverManager
        
        options = Options()
        
        # –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if SELENIUM_HEADLESS:
            options.add_argument('--headless=new')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--disable-blink-features=AutomationControlled')
        
        # –†–µ–∞–ª—å–Ω—ã–π User-Agent
        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –¥–µ—Ç–µ–∫—Ç–∞
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–∫—Å–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if proxy_url:
            normalized_proxy = _normalize_proxy_for_selenium(proxy_url)
            options.add_argument(f'--proxy-server={normalized_proxy}')
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è Selenium: {normalized_proxy}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞
        prefs = {
            "credentials_enable_service": False,
            "profile.password_manager_enabled": False,
            "profile.default_content_setting_values.notifications": 2
        }
        options.add_experimental_option("prefs", prefs)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º WebDriver Manager –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –¥—Ä–∞–π–≤–µ—Ä–∞
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        
        # –°–∫—Ä—ã–≤–∞–µ–º WebDriver
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        return driver
        
    except ImportError as e:
        logger.error(f"‚ùå Selenium –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
        raise ImportError("–î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Selenium —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install selenium webdriver-manager")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Selenium: {e}")
        raise

def _normalize_proxy_for_selenium(proxy_url: str) -> str:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç –ø—Ä–æ–∫—Å–∏ –∫ —Ñ–æ—Ä–º–∞—Ç—É –¥–ª—è Selenium."""
    # –£–¥–∞–ª—è–µ–º —Å—Ö–µ–º—É –µ—Å–ª–∏ –µ—Å—Ç—å
    if proxy_url.startswith(('http://', 'https://')):
        proxy_url = proxy_url.split('://')[1]
    
    # –£–¥–∞–ª—è–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è Selenium (–æ–Ω –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö)
    if '@' in proxy_url:
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ host:port
        proxy_url = proxy_url.split('@')[1]
    
    return proxy_url

def parse_with_selenium(url: str, proxy_url: Optional[str] = None) -> str:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Selenium —Å —ç–º—É–ª—è—Ü–∏–µ–π —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞.
    –û–±—Ö–æ–¥–∏—Ç –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∫–∞–ø—á –∏ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫.
    """
    if not SELENIUM_ENABLED:
        raise ValueError("Selenium –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")
    
    driver = None
    try:
        logger.info(f"ü¶ä Selenium: –Ω–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ {url}")
        start_time = time.time()
        
        driver = init_selenium_driver(proxy_url)
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        driver.get(url)
        
        # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ (—Å–ª—É—á–∞–π–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞)
        wait_time = random.uniform(2, 5)
        time.sleep(wait_time)
        
        # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.3);")
        time.sleep(random.uniform(0.5, 1.5))
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight * 0.7);")
        time.sleep(random.uniform(0.5, 1.5))
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(random.uniform(0.5, 1.5))
        
        # –ü–æ–ª—É—á–∞–µ–º HTML
        html = driver.page_source
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–∞–ø—á—É/–±–ª–æ–∫–∏—Ä–æ–≤–∫—É
        if _detect_captcha(html):
            logger.warning("‚ö†Ô∏è Selenium: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞")
            raise ValueError(GENERIC_VACANCY_ERROR_MSG)
        
        elapsed = time.time() - start_time
        logger.info(f"‚úÖ Selenium: —É—Å–ø–µ—à–Ω–æ –∑–∞ {elapsed:.1f} —Å–µ–∫, {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return html
        
    except Exception as e:
        logger.error(f"‚ùå Selenium –æ—à–∏–±–∫–∞ –¥–ª—è {url}: {e}", exc_info=True)
        raise ValueError(f"Selenium –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É: {str(e)}")
        
    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass

def _detect_captcha(html: str) -> bool:
    """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫–∞–ø—á–∏/–±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤ HTML."""
    if not html:
        return True
    
    html_lower = html.lower()
    
    captcha_indicators = [
        "captcha",
        "cloudflare",
        "are you human",
        "access denied",
        "–ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —á—Ç–æ –≤—ã –Ω–µ —Ä–æ–±–æ—Ç",
        "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ",
        "security check"
    ]
    
    return any(indicator in html_lower for indicator in captcha_indicators)

# =========================
# –ü–†–û–ö–°–ò-–ü–ê–†–°–ò–ù–ì –ß–ï–†–ï–ó REQUESTS (FALLBACK)
# =========================

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
    "Accept-Encoding": "gzip, deflate, br",
    "DNT": "1",
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
    "Sec-Fetch-Dest": "document",
    "Sec-Fetch-Mode": "navigate",
    "Sec-Fetch-Site": "none",
    "Sec-Fetch-User": "?1",
    "Cache-Control": "max-age=0",
}

def _normalize_proxy_url(raw: str) -> str:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç PROXY_URL –∫ –≤–∏–¥—É, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç requests.
    """
    raw = (raw or "").strip()
    if not raw:
        return raw

    # –£–∂–µ –µ—Å—Ç—å —Å—Ö–µ–º–∞
    if re.match(r"^[a-zA-Z0-9+.-]+://", raw):
        return raw

    # –ï—Å–ª–∏ –µ—Å—Ç—å –ª–æ–≥–∏–Ω/–ø–∞—Ä–æ–ª—å –∏ —Ö–æ—Å—Ç
    if "@" in raw:
        left, right = raw.split("@", 1)

        def looks_like_host_port(part: str) -> bool:
            host, _, _ = part.partition(":")
            return "." in host and re.search(r"[a-zA-Z]", host) is not None

        if looks_like_host_port(left):
            host_port = left
            creds = right
        else:
            creds = left
            host_port = right

        return f"http://{creds}@{host_port}"

    return f"http://{raw}"

def fetch_html_via_requests(url: str, proxy_url: Optional[str] = None) -> str:
    """
    –ó–∞–ø—Ä–æ—Å HTML —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ (requests fallback).
    """
    proxies = None
    if proxy_url:
        normalized_proxy = _normalize_proxy_url(proxy_url)
        proxies = {
            "http": normalized_proxy,
            "https": normalized_proxy,
        }
        logger.info(f"üîó Requests —Å –ø—Ä–æ–∫—Å–∏: {normalized_proxy}")

    try:
        logger.info(f"üåê Requests: –ø–∞—Ä—Å–∏–º {url}")
        
        session = requests.Session()
        
        # –î–æ–±–∞–≤–ª—è–µ–º cookies –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –≤–∏–∑–∏—Ç–∞
        session.get('https://google.com', timeout=2, headers=HEADERS, proxies=proxies)
        
        resp = session.get(
            url,
            headers=HEADERS,
            proxies=proxies,
            timeout=20,
        )

        logger.info(f"Requests —Å—Ç–∞—Ç—É—Å: {resp.status_code}")
        resp.raise_for_status()

        html = resp.text

        if _detect_captcha(html):
            logger.warning("‚ö†Ô∏è Requests: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞")
            raise ValueError(GENERIC_VACANCY_ERROR_MSG)

        if len(html) < 500:
            logger.warning(f"‚ö†Ô∏è Requests: –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç ({len(html)} —Å–∏–º–≤–æ–ª–æ–≤)")
            raise ValueError(GENERIC_VACANCY_ERROR_MSG)

        return html

    except requests.exceptions.Timeout:
        logger.error(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ {url}")
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)

    except requests.exceptions.ProxyError as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–∫—Å–∏: {e}")
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)

    except requests.RequestException as e:
        logger.error(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {e}")
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)

    except Exception as e:
        logger.error(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise ValueError(GENERIC_VACANCY_ERROR_MSG)

# =========================
# –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ü–ê–†–°–ï–† (SMART FALLBACK)
# =========================

def fetch_url_text_via_proxy(url: str) -> str:
    """
    –£–º–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏:
    1. Selenium —Å –ø—Ä–æ–∫—Å–∏ (–ª—É—á—à–µ –≤—Å–µ–≥–æ –æ–±—Ö–æ–¥–∏—Ç –∫–∞–ø—á–∏)
    2. Requests —Å –ø—Ä–æ–∫—Å–∏ (–±—ã—Å—Ç—Ä–µ–µ)
    3. Requests –±–µ–∑ –ø—Ä–æ–∫—Å–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–∞—Ä–∏–∞–Ω—Ç)
    """
    methods_to_try = []
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ –º–µ—Ç–æ–¥—ã –¥–æ—Å—Ç—É–ø–Ω—ã
    if SELENIUM_ENABLED and PROXY_URL:
        methods_to_try.append(("Selenium —Å –ø—Ä–æ–∫—Å–∏", lambda: parse_with_selenium(url, PROXY_URL)))
    
    if PROXY_URL:
        methods_to_try.append(("Requests —Å –ø—Ä–æ–∫—Å–∏", lambda: fetch_html_via_requests(url, PROXY_URL)))
    
    methods_to_try.append(("Requests –±–µ–∑ –ø—Ä–æ–∫—Å–∏", lambda: fetch_html_via_requests(url, None)))
    
    # –ü—Ä–æ–±—É–µ–º –º–µ—Ç–æ–¥—ã –ø–æ –ø–æ—Ä—è–¥–∫—É
    for method_name, parser_func in methods_to_try:
        try:
            logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º {method_name} –¥–ª—è {url}")
            html = parser_func()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
            text = html_to_text(html)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
            if text and len(text) >= MIN_MEANINGFUL_TEXT_LENGTH:
                logger.info(f"‚úÖ {method_name} —É—Å–ø–µ—à–µ–Ω: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                return text
            else:
                logger.warning(f"‚ö†Ô∏è {method_name}: –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ ({len(text) if text else 0} —Å–∏–º–≤–æ–ª–æ–≤)")
                
        except ValueError as e:
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –æ—à–∏–±–∫–∞ - –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º
            raise e
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è {method_name} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
            continue
    
    # –í—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏
    logger.error(f"‚ùå –í—Å–µ –º–µ—Ç–æ–¥—ã –ø–∞—Ä—Å–∏–Ω–≥–∞ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ –¥–ª—è {url}")
    raise ValueError(GENERIC_VACANCY_ERROR_MSG)
