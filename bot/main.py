import os
import logging
from typing import Any, Dict, List, cast
import re
import time
import random
import json
import asyncio
from urllib.parse import urlparse, urljoin
import requests
from bs4 import BeautifulSoup
from io import BytesIO
from PyPDF2 import PdfReader
from playwright.sync_api import sync_playwright

from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from openai import OpenAI
from openai.types.chat import ChatCompletionMessageParam

# Enable logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Initialize OpenAI client
openai_client = None


def get_browser_headers() -> dict:
    """–ü–æ–ª–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞."""
    user_agents = [
        # Chrome –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–µ—Ä—Å–∏–∏
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0",
        # Firefox
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:123.0) Gecko/20100101 Firefox/123.0",
    ]
    
    headers = {
        'User-Agent': random.choice(user_agents),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0',
        'Pragma': 'no-cache',
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ Cloudflare
    headers.update({
        'sec-ch-ua': '"Chromium";v="122", "Not(A:Brand";v="24", "Google Chrome";v="122"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'DNT': '1',
        'Sec-GPC': '1',
    })
    
    return headers


def render_page_with_playwright(url: str,
                                headers: Dict[str, str],
                                timeout_ms: int = 15000) -> str:
    """Fetch fully rendered HTML with Playwright to bypass simple anti-bot walls."""
    logger.info(f"Playwright: rendering {url}")
    extra_headers = {
        k: v for k, v in headers.items()
        if k.lower() not in ["user-agent", "host"]
    }
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            context = browser.new_context(
                user_agent=headers.get("User-Agent"),
                extra_http_headers=extra_headers,
            )
            page = context.new_page()
            page.goto(url, wait_until="networkidle", timeout=timeout_ms)
            page.wait_for_timeout(random.randint(500, 1200))
            html = page.content()
            context.close()
            browser.close()
            logger.info(f"Playwright: rendered {url} (len={len(html)})")
            return html
    except Exception as e:
        logger.info(f"Playwright render failed for {url}: {e}")
        return ""


def load_system_prompt() -> str:
    """Load the system prompt from system_prompt.txt if it exists."""
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(base_dir, "system_prompt.txt")
        with open(file_path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "You are a helpful assistant."
    except Exception as e:
        logger.warning(f"Failed to load system_prompt.txt: {e}")
        return "You are a helpful assistant."


# =========================
# –ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ / —Å—Å—ã–ª–æ–∫ / PDF
# =========================

def clean_text(raw: str) -> str:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –≤ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –≤–∏–¥."""
    if not raw:
        return ""
    text = raw.replace("\r\n", "\n")
    lines = [line.strip() for line in text.split("\n")]
    text = "\n".join(lines)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()


def is_url(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Ö–æ–∂–∞ –ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞ URL."""
    if not text:
        return False
    text = text.strip()
    
    # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
    if re.match(r'^https?://\S+$', text, re.IGNORECASE):
        return True
    if re.match(r'^www\.\S+\.\S+$', text, re.IGNORECASE):
        return True
    
    try:
        parsed = urlparse(text)
        return bool(parsed.netloc)
    except:
        return False


def extract_text_from_pdf_bytes(data: bytes) -> str:
    """–î–æ—Å—Ç–∞—ë–º —Ç–µ–∫—Å—Ç –∏–∑ PDF –ø–æ —Å—ã—Ä—ã–º –±–∞–π—Ç–∞–º."""
    try:
        reader = PdfReader(BytesIO(data))
        pages_text: List[str] = []
        for page in reader.pages:
            page_text = page.extract_text() or ""
            pages_text.append(page_text)
        return clean_text("\n\n".join(pages_text))
    except Exception as e:
        logger.error(f"Error while extracting text from PDF bytes: {e}")
        return ""


def try_smart_parsing(url: str) -> str:
    """
    –£–º–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –æ–±—Ö–æ–¥–æ–º –∑–∞—â–∏—Ç—ã.
    –î–ª—è tochka.com –∏ –ø–æ–¥–æ–±–Ω—ã—Ö —Å–∞–π—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é.
    """
    parsed = urlparse(url)
    domain = parsed.netloc.lower()
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è tochka.com
    if 'tochka.com' in domain:
        logger.info(f"Using special strategy for tochka.com")
        return _try_tochka_special(url)
    
    # –î–ª—è –¥—Ä—É–≥–∏—Ö —Å–∞–π—Ç–æ–≤ - –æ–±—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
    return _try_general_parsing(url)


def _try_tochka_special(url: str) -> str:
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–ª—è tochka.com."""
    
    # –î–ª—è tochka.com –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –∏—Ö –≤–æ–∑–º–æ–∂–Ω—ã–π API –∏–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—É—Ç–∏
    headers = get_browser_headers()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è tochka.com
    headers.update({
        'Referer': 'https://tochka.com/',
        'Origin': 'https://tochka.com',
        'Host': 'tochka.com',
    })
    
    # Try headless browser first to avoid 403 blocks
    logger.info("Playwright attempt for tochka.com URL")
    rendered_html = render_page_with_playwright(url, headers)
    if rendered_html:
        parsed = _parse_html_content(rendered_html, url)
        if parsed:
            return parsed
    else:
        logger.info("Playwright returned empty content for tochka.com")
    
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
    endpoints_to_try = [
        url,  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL
        url + '.json',  # –í–æ–∑–º–æ–∂–Ω—ã–π JSON endpoint
        url.replace('/hr/', '/api/vacancies/'),  # –í–æ–∑–º–æ–∂–Ω—ã–π API –ø—É—Ç—å
    ]
    
    for endpoint in endpoints_to_try:
        try:
            logger.info(f"Trying endpoint: {endpoint}")
            
            # –ë–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è tochka.com
            time.sleep(random.uniform(3, 5))
            
            response = requests.get(
                endpoint,
                headers=headers,
                timeout=30,
                allow_redirects=True,
                verify=True
            )
            
            logger.info(f"Response status for {endpoint}: {response.status_code}")
            
            if response.status_code == 200:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ JSON –ª–∏ —ç—Ç–æ
                content_type = response.headers.get('Content-Type', '').lower()
                if 'json' in content_type:
                    try:
                        data = response.json()
                        return _parse_json_vacancy(data)
                    except:
                        pass
                
                # –ü—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å HTML
                return _parse_html_content(response.text, url)
                
        except Exception as e:
            logger.debug(f"Endpoint {endpoint} failed: {e}")
            continue
    
    # –ï—Å–ª–∏ –≤—Å–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ç—è –±—ã –∑–∞–≥–æ–ª–æ–≤–æ–∫
    try:
        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ title —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        response = requests.head(url, headers=headers, timeout=10)
        return f"–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é tochka.com: {url}"
    except:
        raise RuntimeError("TOCHKA_BLOCKED")


def _parse_json_vacancy(data: dict) -> str:
    """–ü–∞—Ä—Å–∏–Ω–≥ JSON –¥–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–∏."""
    result = []
    
    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    if isinstance(data, dict):
        # –ü—Ä—è–º—ã–µ –ø–æ–ª—è
        for key in ['title', 'name', 'position']:
            if key in data and data[key]:
                result.append(f"–î–æ–ª–∂–Ω–æ—Å—Ç—å: {data[key]}")
                break
        
        # –û–ø–∏—Å–∞–Ω–∏–µ
        for key in ['description', 'content', 'body', 'text']:
            if key in data and data[key]:
                result.append(f"–û–ø–∏—Å–∞–Ω–∏–µ: {data[key]}")
                break
        
        # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è
        for key in ['requirements', 'qualifications', 'skills', 'experience']:
            if key in data and data[key]:
                if isinstance(data[key], list):
                    result.append(f"{key}: " + ", ".join(str(x) for x in data[key]))
                else:
                    result.append(f"{key}: {data[key]}")
        
        # –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏
        for key in ['responsibilities', 'tasks', 'duties']:
            if key in data and data[key]:
                if isinstance(data[key], list):
                    result.append(f"{key}: " + ", ".join(str(x) for x in data[key]))
                else:
                    result.append(f"{key}: {data[key]}")
    
    return "\n".join(result) if result else ""


def _parse_html_content(html: str, url: str) -> str:
    """–ü–∞—Ä—Å–∏–Ω–≥ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞."""
    try:
        soup = BeautifulSoup(html, 'html.parser')
        
        # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for tag in soup(['script', 'style', 'noscript', 'iframe', 'svg']):
            tag.decompose()
        
        # –ò—â–µ–º title
        title = soup.find('title')
        title_text = title.get_text(strip=True) if title else ""
        
        # –ò—â–µ–º h1
        h1 = soup.find('h1')
        h1_text = h1.get_text(strip=True) if h1 else ""
        
        # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
        content_selectors = [
            'main', 'article', 
            '[class*="vacancy"]', '[class*="job"]', '[class*="description"]',
            '[class*="content"]', '.container', '.wrapper'
        ]
        
        main_content = ""
        for selector in content_selectors:
            try:
                elements = soup.select(selector)
                for elem in elements:
                    text = elem.get_text(separator='\n', strip=True)
                    if len(text) > 200:
                        main_content = text
                        break
                if main_content:
                    break
            except:
                continue
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_parts = []
        if title_text:
            result_parts.append(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title_text}")
        if h1_text and h1_text != title_text:
            result_parts.append(f"H1: {h1_text}")
        if main_content:
            result_parts.append(f"–ö–æ–Ω—Ç–µ–Ω—Ç:\n{main_content}")
        
        if result_parts:
            return "\n\n".join(result_parts)
        else:
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            return f"–í–∞–∫–∞–Ω—Å–∏—è: {title_text or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}\nURL: {url}"
            
    except Exception as e:
        logger.error(f"HTML parsing error: {e}")
        return f"–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é: {url}"


def _try_general_parsing(url: str) -> str:
    """–û–±—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–∞–π—Ç–æ–≤."""
    session = requests.Session()
    
    # –ü–æ–ª–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –±—Ä–∞—É–∑–µ—Ä–∞
    headers = get_browser_headers()
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ—Ñ–µ—Ä–µ—Ä
    parsed = urlparse(url)
    headers['Referer'] = f"{parsed.scheme}://{parsed.netloc}/"
    logger.info(f"Playwright attempt for general URL: {url}")
    
    session.headers.update(headers)
    
    try:
        # –≠–º—É–ª—è—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –±—Ä–∞—É–∑–µ—Ä–∞
        # First try rendered page via Playwright to bypass JS/anti-bot gates
        html = render_page_with_playwright(url, headers)
        if html:
            parsed_html = _parse_html_content(html, url)
            if parsed_html:
                return parsed_html
        else:
            logger.info(f"Playwright returned empty content for general URL: {url}")

        
        # 1. –°–Ω–∞—á–∞–ª–∞ –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        try:
            home_url = f"{parsed.scheme}://{parsed.netloc}/"
            session.get(home_url, timeout=10)
            time.sleep(random.uniform(1, 2))
        except:
            pass
        
        # 2. –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –æ—Å–Ω–æ–≤–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
        time.sleep(random.uniform(2, 3))
        
        # 3. –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å
        response = session.get(url, timeout=25, allow_redirects=True)
        
        logger.info(f"General parsing for {url}: {response.status_code}")
        
        if response.status_code == 403:
            # –ü—Ä–æ–±—É–µ–º —Å –¥—Ä—É–≥–∏–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
            time.sleep(3)
            alt_headers = headers.copy()
            alt_headers['User-Agent'] = get_browser_headers()['User-Agent']  # –ù–æ–≤—ã–π User-Agent
            
            response = requests.get(url, headers=alt_headers, timeout=25)
            if response.status_code == 403:
                raise RuntimeError("ACCESS_DENIED")
        
        if response.status_code != 200:
            response.raise_for_status()
        
        # –ü–∞—Ä—Å–∏–º –∫–æ–Ω—Ç–µ–Ω—Ç
        return _parse_html_content(response.text, url)
        
    except requests.HTTPError as e:
        if e.response.status_code == 403:
            raise RuntimeError("ACCESS_DENIED")
        elif e.response.status_code == 404:
            raise RuntimeError("NOT_FOUND")
        else:
            raise RuntimeError(f"HTTP_ERROR_{e.response.status_code}")
    except requests.RequestException as e:
        logger.error(f"Request error: {e}")
        raise RuntimeError("NETWORK_ERROR")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        raise RuntimeError("PARSING_ERROR")
    finally:
        session.close()


def extract_text_from_url(url: str) -> str:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ URL."""
    logger.info(f"Parsing URL: {url}")
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    try:
        return try_smart_parsing(url)
    except RuntimeError as e:
        error_type = str(e)
        logger.warning(f"Smart parsing failed for {url}: {error_type}")
        
        # –î–ª—è tochka.com –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Å—ã–ª–∫—É –∫–∞–∫ —Ç–µ–∫—Å—Ç
        parsed = urlparse(url)
        if 'tochka.com' in parsed.netloc.lower():
            return f"–í–∞–∫–∞–Ω—Å–∏—è –Ω–∞ tochka.com: {url}"
        
        raise e


def prepare_input_text(raw: str) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–≤–æ–¥–∞.
    –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç, –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π.
    """
    if not raw:
        return ""
    
    raw = raw.strip()
    
    # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å—Å—ã–ª–∫–∞, –ø—Ä–æ—Å—Ç–æ —á–∏—Å—Ç–∏–º —Ç–µ–∫—Å—Ç
    if not is_url(raw):
        return clean_text(raw)
    
    # –ï—Å–ª–∏ —ç—Ç–æ —Å—Å—ã–ª–∫–∞ - –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å
    logger.info(f"Processing URL: {raw}")
    
    try:
        text = extract_text_from_url(raw)
        if text and len(text.strip()) > 50:
            return text
        else:
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
            return clean_text(f"–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é: {raw}")
            
    except RuntimeError as e:
        error_type = str(e)
        logger.info(f"Could not parse URL {raw}: {error_type}")
        
        # –í–û–ó–í–†–ê–©–ê–ï–ú –°–°–´–õ–ö–£ –ö–ê–ö –¢–ï–ö–°–¢ –í –õ–Æ–ë–û–ú –°–õ–£–ß–ê–ï
        parsed = urlparse(raw)
        if 'tochka.com' in parsed.netloc.lower():
            return clean_text(f"–í–∞–∫–∞–Ω—Å–∏—è –Ω–∞ tochka.com: {raw}")
        elif 'hh.ru' in parsed.netloc.lower():
            return clean_text(f"–í–∞–∫–∞–Ω—Å–∏—è –Ω–∞ hh.ru: {raw}")
        else:
            return clean_text(f"–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é: {raw}")
            
    except Exception as e:
        logger.error(f"Unexpected error parsing URL {raw}: {e}")
        # –í—Å–µ —Ä–∞–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Å—ã–ª–∫—É –∫–∞–∫ —Ç–µ–∫—Å—Ç
        return clean_text(f"–°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—é: {raw}")


# =========================
# Telegram Bot Handlers (–æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
# =========================

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Send a message when the command /start is issued."""
    message = update.message
    if message is None:
        logger.warning("Received /start update without message")
        return

    user = update.effective_user
    if user is None:
        await message.reply_text(
            "–ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ –ø–æ–∏—Å–∫–µ —Ä–∞–±–æ—Ç—ã –∏ –ø–æ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–º –ø–∏—Å—å–º–∞–º. "
            "–û—Ç–ø—Ä–∞–≤—å —Ä–µ–∑—é–º–µ –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ –Ω–µ–≥–æ, –∞ —è –ø–æ–¥–±–µ—Ä—É —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏ —Å–æ–±–µ—Ä—É –ø–∏—Å—å–º–∞ –ø–æ–¥ –Ω—É–∂–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏"
        )
        return

    await message.reply_html(
        rf"–ü—Ä–∏–≤–µ—Ç {user.mention_html()}! –Ø —Ç–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫ –≤ –ø–æ–∏—Å–∫–µ —Ä–∞–±–æ—Ç—ã –∏ –ø–æ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–º –ø–∏—Å—å–º–∞–º. "
        rf"–û—Ç–ø—Ä–∞–≤—å —Ä–µ–∑—é–º–µ –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ –Ω–µ–≥–æ, –∞ —è –ø–æ–¥–±–µ—Ä—É —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏ —Å–æ–±–µ—Ä—É –ø–∏—Å—å–º–∞ –ø–æ–¥ –Ω—É–∂–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏"
    )


async def help_command(update: Update,
                       context: ContextTypes.DEFAULT_TYPE) -> None:
    """Send a message when the command /help is issued."""
    message = update.message
    if message is None:
        logger.warning("Received /help update without message")
        return

    help_text = """
–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/start - –ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞
/help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–º–æ—â–∏
/update_resume - –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –≤–∞—à–µ–≥–æ –æ–ø—ã—Ç–∞

–Ø –ø–æ–º–æ–≥—É –≤–∞–º —Å:
- –ê–Ω–∞–ª–∏–∑–æ–º –≤–∞–∫–∞–Ω—Å–∏–π
- –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º —Å –≤–∞—à–∏–º —Ä–µ–∑—é–º–µ
- –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∏—Å–µ–º
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–æ–π –∫ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è–º

–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ:
1. –í–∞—à–µ —Ä–µ–∑—é–º–µ (—Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ PDF)
2. –°—Å—ã–ª–∫—É –Ω–∞ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â—É—é –≤–∞–∫–∞–Ω—Å–∏—é
3. –ò–ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Ç–µ–∫—Å—Ç–æ–º

üìå –°–æ–≤–µ—Ç: –î–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–π –≤—Ä—É—á–Ω—É—é.
    """
    await message.reply_text(help_text)


async def update_resume(update: Update,
                        context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /update_resume command."""
    message = update.message
    if message is None:
        logger.warning("Received /update_resume update without message")
        return

    user_data = cast(Dict[str, Any], context.user_data)
    user_data['awaiting_resume'] = True
    user_data.pop('resume', None)
    await message.reply_text("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –≤–∞—à–µ–≥–æ –æ–ø—ã—Ç–∞")


async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle user messages with OpenAI."""
    message = update.message
    if message is None:
        logger.warning("Received text update without message in chat handler")
        return

    if not openai_client:
        await message.reply_text(
            "Sorry, OpenAI is not configured. Please set the OPENAI_API_KEY environment variable."
        )
        return

    user_data = cast(Dict[str, Any], context.user_data)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –æ—Ç–∫—É–¥–∞ –±—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç: PDF –∏–ª–∏ —Ç–µ–∫—Å—Ç
    user_message: str

    if message.document is not None:
        doc = message.document
        is_pdf = (
            doc.mime_type == "application/pdf"
            or (doc.file_name and doc.file_name.lower().endswith(".pdf"))
        )

        if not is_pdf:
            await message.reply_text(
                "–°–µ–π—á–∞—Å —è —É–º–µ—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ PDF-—Ñ–∞–π–ª—ã –∏ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è."
            )
            return

        try:
            file = await doc.get_file()
            bio = BytesIO()
            await file.download_to_memory(out=bio)
            pdf_bytes = bio.getvalue()
            extracted = extract_text_from_pdf_bytes(pdf_bytes)
            if not extracted:
                await message.reply_text(
                    "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç."
                )
                return
            user_message = extracted
        except Exception as e:
            logger.error(f"Error while downloading/reading PDF: {e}")
            await message.reply_text(
                "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ PDF-—Ñ–∞–π–ª–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç."
            )
            return

    else:  # —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        raw_text = message.text
        if raw_text is None:
            await message.reply_text("–Ø –º–æ–≥—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –∏–ª–∏ PDF-—Ñ–∞–π–ª—ã.")
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –±–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç
        await message.chat.send_action(action="typing")
        
        # –í–°–ï–ì–î–ê –ø–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç, –¥–∞–∂–µ –µ—Å–ª–∏ —ç—Ç–æ —Å—Å—ã–ª–∫–∞
        user_message = await asyncio.to_thread(prepare_input_text, raw_text)

    # –ï—Å–ª–∏ –æ–∂–∏–¥–∞–µ–º –Ω–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –ø–æ—Å–ª–µ /update_resume ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –∏ –Ω–µ –≤—ã–∑—ã–≤–∞–µ–º OpenAI
    if user_data.get("awaiting_resume"):
        user_data["resume"] = user_message
        user_data["awaiting_resume"] = False
        await message.reply_text(
            "‚úÖ –°–ø–∞—Å–∏–±–æ! –Ø –æ–±–Ω–æ–≤–∏–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∞—à–µ–º –æ–ø—ã—Ç–µ.\n\n"
            "–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é –∏–ª–∏ –≤–æ–ø—Ä–æ—Å, "
            "–∏ —è –±—É–¥—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ —Ä–µ–∑—é–º–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."
        )
        return

    try:
        # Send typing action to show the bot is processing
        await message.chat.send_action(action="typing")

        system_prompt = load_system_prompt()

        # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é/—á–∞—Ç—É
        history = cast(List[Dict[str, str]], user_data.get("history", []))
        max_history_messages = 10

        messages: List[ChatCompletionMessageParam] = [
            {
                "role": "system",
                "content": system_prompt
            }
        ]

        if history:
            messages.extend(history[-max_history_messages:])

        # –ï—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ä–µ–∑—é–º–µ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ-–∫–æ–Ω—Ç–µ–∫—Å—Ç
        resume = user_data.get("resume")
        if resume:
            messages.append({
                "role": "user",
                "content": (
                    "–≠—Ç–æ —Ä–µ–∑—é–º–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ò—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç "
                    "–ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤–∞–∫–∞–Ω—Å–∏–π, —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–∏—Å–µ–º:\n\n"
                    f"{resume}"
                ),
            })

        # –¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        messages.append({
            "role": "user",
            "content": user_message
        })

        # Call OpenAI API
        response = openai_client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=messages,
            max_completion_tokens=2048
        )

        ai_response = response.choices[0].message.content or (
            "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç."
        )
        await message.reply_text(ai_response)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é: user ‚Üí assistant
        if ai_response:
            history.append({"role": "user", "content": user_message})
            history.append({"role": "assistant", "content": ai_response})
            user_data["history"] = history[-max_history_messages:]

    except Exception as e:
        logger.error(f"Error calling OpenAI API: {e}")
        await message.reply_text(
            "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."
        )


async def error_handler(update: Update,
                        context: ContextTypes.DEFAULT_TYPE) -> None:
    """Log errors caused by updates."""
    logger.error(f"Update {update} caused error {context.error}")


def main() -> None:
    """Start the bot."""
    global openai_client

    # Get the bot token from environment variable
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    openai_api_key = os.getenv('OPENAI_API_KEY')

    if not token:
        logger.error("TELEGRAM_BOT_TOKEN not found in environment variables!")
        print(
            "ERROR: Please set your TELEGRAM_BOT_TOKEN environment variable."
        )
        print("You can get a token from @BotFather on Telegram.")
        return

    if not openai_api_key:
        logger.warning("OPENAI_API_KEY not found in environment variables!")
        print(
            "WARNING: OpenAI API key not set. The bot will run but AI features won't work."
        )
        print("Please set your OPENAI_API_KEY to enable AI responses.")
    else:
        # Initialize OpenAI client
        openai_client = OpenAI(api_key=openai_api_key)
        logger.info("OpenAI client initialized successfully")

    # Create the Application
    application = Application.builder().token(token).build()

    # Register command handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("update_resume", update_resume))

    # Register message handler for —Ç–µ–∫—Å—Ç + PDF
    application.add_handler(
        MessageHandler(
            (filters.TEXT | filters.Document.PDF) & ~filters.COMMAND,
            chat,
        )
    )

    # Register error handler
    application.add_error_handler(error_handler)

    # Start the bot
    logger.info("Bot is starting...")
    print("Bot is running! Press Ctrl+C to stop.")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == '__main__':
    main()
